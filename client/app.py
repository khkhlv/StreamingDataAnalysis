#!/usr/bin/env python3
"""
–í–µ–±-—Å–µ—Ä–≤–µ—Ä —Å –∫–ª–∞—Å—Ç–µ—Ä–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º (—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ —Ä–∞–±–æ—á–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö)
"""

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Request
from fastapi.responses import HTMLResponse
from fastapi.templating import Jinja2Templates
from kafka import KafkaConsumer
import json
import asyncio
from threading import Thread, Lock
import time
from collections import defaultdict, deque
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# –ò–°–ü–†–ê–í–õ–ï–ù–û: –ø–∞–ø–∫–∞ —à–∞–±–ª–æ–Ω–æ–≤ "client" –≤–º–µ—Å—Ç–æ "templates" (–∫–∞–∫ –≤ –≤–∞—à–µ–º —Ä–∞–±–æ—á–µ–º –∫–æ–¥–µ)
app = FastAPI(title="Moex Stream Analyzer")
templates = Jinja2Templates(directory=".")  # ‚Üê –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: "client" –∞ –Ω–µ "templates"
connections = {"main": set(), "clusters": set()}
event_loop = None
lock = Lock()

# –ö—ç—à –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ (–æ—Ç–¥–µ–ª—å–Ω–æ –æ—Ç –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∫—ç—à–∞)
cluster_cache = defaultdict(lambda: {
    "prices": deque(maxlen=60),
    "volatilities": deque(maxlen=60),
    "volumes": deque(maxlen=60),
    "rsi": deque(maxlen=60),
    "sma_ratio": deque(maxlen=60)
})
cluster_results = {"clusters": {}, "last_update": 0}

@app.get("/", response_class=HTMLResponse)
async def root(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

# –ù–û–í–ê–Ø –°–¢–†–ê–ù–ò–¶–ê: –∫–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑
@app.get("/clusters", response_class=HTMLResponse)
async def clusters_page(request: Request):
    return templates.TemplateResponse("cluster.html", {"request": request})

@app.websocket("/ws")
async def websocket_main(websocket: WebSocket):
    """–û—Å–Ω–æ–≤–Ω–æ–π –≤–µ–±-—Å–æ–∫–µ—Ç (–∫–∞–∫ –≤ –≤–∞—à–µ–º —Ä–∞–±–æ—á–µ–º –∫–æ–¥–µ)"""
    await websocket.accept()
    connections["main"].add(websocket)
    print(f"\n‚úÖ WebSocket –ø–æ–¥–∫–ª—é—á–µ–Ω. –í—Å–µ–≥–æ –∫–ª–∏–µ–Ω—Ç–æ–≤: {len(connections['main'])}")
    
    try:
        if hasattr(app.state, 'latest_data'):
            for ticker, data in app.state.latest_data.items():
                await websocket.send_json(data)
        while True:
            await websocket.receive_text()
    except WebSocketDisconnect:
        connections["main"].discard(websocket)
        print(f"üîå WebSocket –æ—Ç–∫–ª—é—á–µ–Ω. –û—Å—Ç–∞–ª–æ—Å—å –∫–ª–∏–µ–Ω—Ç–æ–≤: {len(connections['main'])}")

# –ù–û–í–´–ô –í–ï–ë-–°–û–ö–ï–¢: –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
@app.websocket("/ws/clusters")
async def websocket_clusters(websocket: WebSocket):
    await websocket.accept()
    connections["clusters"].add(websocket)
    print(f"‚úÖ –ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π WebSocket –ø–æ–¥–∫–ª—é—á–µ–Ω. –ö–ª–∏–µ–Ω—Ç–æ–≤: {len(connections['clusters'])}")
    
    try:
        if cluster_results["clusters"]:
            await websocket.send_json({
                "type": "clusters",
                "data": cluster_results["clusters"],
                "timestamp": cluster_results["last_update"]
            })
        while True:
            await websocket.receive_text()
    except WebSocketDisconnect:
        connections["clusters"].discard(websocket)
        print(f"üîå –ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π WebSocket –æ—Ç–∫–ª—é—á–µ–Ω. –û—Å—Ç–∞–ª–æ—Å—å: {len(connections['clusters'])}")

def kafka_reader():
    """–ß–∏—Ç–∞—Ç–µ–ª—å —Å –í–ê–®–ï–ô —Ä–∞–±–æ—á–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –¥–∞–Ω–Ω—ã—Ö (–≤–ª–æ–∂–µ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞)"""
    print("\n" + "="*70)
    print("üì° –ó–∞–ø—É—Å–∫ —á–∏—Ç–∞—Ç–µ–ª—è Kafka (–í–ê–®–ê –†–ê–ë–û–ß–ê–Ø –°–¢–†–£–ö–¢–£–†–ê)")
    print("="*70)
    
    group_id = f"web-client-main-{int(time.time())}"
    
    try:
        consumer = KafkaConsumer(
            'moex_indicators',
            bootstrap_servers='kafka:9092',
            auto_offset_reset='latest',
            enable_auto_commit=True,
            group_id=group_id,
            value_deserializer=lambda x: json.loads(x.decode('utf-8'))
        )
        
        print(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ Kafka (–≥—Ä—É–ø–ø–∞: {group_id})")
        print("‚è≥ –ß—Ç–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ —Ç–æ–ø–∏–∫–∞ 'moex_indicators'...\n")
        
        if not hasattr(app.state, 'latest_data'):
            app.state.latest_data = {}
        
        # –î–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å –≤ –¥—Ä—É–≥–æ–º –ø–æ—Ç–æ–∫–µ
        Thread(target=cluster_kafka_reader, daemon=True).start()
        
        message_count = 0
        last_cluster_time = time.time()
        
        for msg in consumer:
            try:
                data = msg.value
                
                ohlcv = data.get("ohlcv", {})
                indicators = data.get("indicators", {})
                sma = indicators.get("sma", {})
                rsi_data = indicators.get("rsi", {})
                signals = data.get("signals", {})
                
                formatted = {
                    "ticker": data.get("ticker", "UNKNOWN"),
                    "price": ohlcv.get("close", 0),
                    "sma_5": sma.get("sma_5", 0),
                    "sma_20": sma.get("sma_20", 0),
                    "rsi": rsi_data.get("value", 50),
                    "volatility": indicators.get("volatility", 0),
                    "volume": ohlcv.get("volume", 0),
                    "signals": {
                        "summary": signals.get("summary", [])
                    }
                }
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫—ç—à
                app.state.latest_data[formatted["ticker"]] = formatted
                
                # –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ (–ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ)
                with lock:
                    ticker = formatted["ticker"]
                    cluster_cache[ticker]["prices"].append(formatted["price"])
                    cluster_cache[ticker]["volatilities"].append(formatted["volatility"])
                    cluster_cache[ticker]["volumes"].append(formatted["volume"])
                    cluster_cache[ticker]["rsi"].append(formatted["rsi"])
                    cluster_cache[ticker]["sma_ratio"].append(
                        formatted["sma_5"] / formatted["sma_20"] if formatted["sma_20"] > 0 else 1.0
                    )
                
                # –†–∞—Å—Å—ã–ª–∫–∞ –æ—Å–Ω–æ–≤–Ω—ã–º –∫–ª–∏–µ–Ω—Ç–∞–º
                if connections["main"] and event_loop:
                    asyncio.run_coroutine_threadsafe(
                        broadcast_main(formatted),
                        event_loop
                    )
                trend_signal = None
                for signal in signals.get("summary", []):
                    if "–í–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥" in signal:
                        trend_signal = "up"
                        break
                    elif "–ù–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥" in signal:
                        trend_signal = "down"
                        break
                
                if trend_signal and len(connections.get("trend", [])) > 0:
                    with lock:
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ü–µ–Ω—É –≤ –∏—Å—Ç–æ—Ä–∏—é
                        trend_history[ticker].append(formatted["price"])
                        
                        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –ø—Ä–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö
                        if len(trend_history[ticker]) >= 10:
                            history_list = list(trend_history[ticker])
                            display_history = history_list[-20:] if len(history_list) >= 20 else history_list
                            
                            # –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
                            x = np.arange(len(history_list))
                            y = np.array(history_list)
                            coeffs = np.polyfit(x, y, 1)
                            poly = np.poly1d(coeffs)
                            
                            # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 5 —Å–µ–∫—É–Ω–¥ –≤–ø–µ—Ä–µ–¥
                            forecast_x = np.arange(len(history_list), len(history_list) + 5)
                            forecast_y = poly(forecast_x).tolist()
                            
                            # –û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç—É
                            trend_data = {
                                "type": "trend_update",
                                "ticker": ticker,
                                "current_price": formatted["price"],
                                "trend_type": trend_signal,
                                "history": display_history,
                                "forecast": forecast_y,
                                "timestamp": data.get("timestamp", "")
                            }
                            
                            if event_loop:
                                asyncio.run_coroutine_threadsafe(
                                    broadcast_trend(trend_data),
                                    event_loop
                                )
                
                # –ó–∞–ø—É—Å–∫ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫
                now = time.time()
                if now - last_cluster_time >= 30 and len(cluster_cache) >= 3:
                    last_cluster_time = now
                    Thread(target=perform_clustering, daemon=True).start()
                
                message_count += 1
                if message_count == 1:
                    print("üéâ –ü–ï–†–í–´–ï –î–ê–ù–ù–´–ï –ü–û–õ–£–ß–ï–ù–´ (–∫–∞–∫ –≤ –≤–∞—à–µ–º —Ä–∞–±–æ—á–µ–º –∫–æ–¥–µ)!")
                    print(f"   –¢–∏–∫–µ—Ä: {formatted['ticker']} | –¶–µ–Ω–∞: {formatted['price']:.2f} ‚ÇΩ | RSI: {formatted['rsi']:.1f}")
                elif message_count % 20 == 0:
                    print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {message_count} —Å–æ–æ–±—â–µ–Ω–∏–π. –ü–æ—Å–ª–µ–¥–Ω–∏–π: {formatted['ticker']} @ {formatted['price']:.2f} ‚ÇΩ")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
        
        consumer.close()
        
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ Kafka: {e}")
        import traceback
        traceback.print_exc()

def cluster_kafka_reader():
    """–û—Ç–¥–µ–ª—å–Ω—ã–π –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å –¢–û–õ–¨–ö–û –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ (–Ω–µ –≤–ª–∏—è–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫)"""
    # –≠—Ç–æ—Ç –ø–æ—Ç–æ–∫ –Ω–µ –Ω—É–∂–µ–Ω - –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞
    # –û—Å—Ç–∞–≤–ª–µ–Ω –¥–ª—è –±—É–¥—É—â–µ–≥–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
    pass

async def broadcast_main(data):
    """–†–∞—Å—Å—ã–ª–∫–∞ –æ—Å–Ω–æ–≤–Ω—ã–º –∫–ª–∏–µ–Ω—Ç–∞–º"""
    disconnected = set()
    for ws in connections["main"]:
        try:
            await ws.send_json(data)
        except:
            disconnected.add(ws)
    
    for ws in disconnected:
        connections["main"].discard(ws)

async def broadcast_clusters(data):
    """–†–∞—Å—Å—ã–ª–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–Ω—ã–º –∫–ª–∏–µ–Ω—Ç–∞–º"""
    disconnected = set()
    for ws in connections["clusters"]:
        try:
            await ws.send_json(data)
        except:
            disconnected.add(ws)
    
    for ws in disconnected:
        connections["clusters"].discard(ws)

def perform_clustering():
    """–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    try:
        with lock:
            tickers = list(cluster_cache.keys())
            if len(tickers) < 3:
                return
            
            features = []
            valid_tickers = []
            
            for ticker in tickers:
                t = cluster_cache[ticker]
                if len(t["prices"]) < 10:  # –ú–∏–Ω–∏–º—É–º 10 —Ç–æ—á–µ–∫
                    continue
                
                features.append([
                    np.mean(t["prices"]),
                    np.std(t["prices"]),
                    np.mean(t["volatilities"]),
                    np.mean(t["volumes"]),
                    np.mean(t["rsi"]),
                    np.mean(t["sma_ratio"])
                ])
                valid_tickers.append(ticker)
            
            if len(features) < 2:
                return
            
            features = np.array(features)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            scaler = StandardScaler()
            features_scaled = scaler.fit_transform(features)
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∏—Å–ª–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
            n_clusters = min(max(2, len(valid_tickers) // 3), 5)
            
            # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            cluster_labels = kmeans.fit_predict(features_scaled)
            
            # –°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
            pca = PCA(n_components=2, random_state=42)
            features_2d = pca.fit_transform(features_scaled)
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            cluster_results["clusters"] = {
                "tickers": valid_tickers,
                "labels": cluster_labels.tolist(),
                "features_2d": features_2d.tolist(),
                "centroids_2d": pca.transform(kmeans.cluster_centers_).tolist(),
                "n_clusters": n_clusters
            }
            cluster_results["last_update"] = time.time()
            
            # –û—Ç–ª–∞–¥–æ—á–Ω—ã–π –≤—ã–≤–æ–¥
            print(f"\nüìä –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø –í–´–ü–û–õ–ù–ï–ù–ê ({len(valid_tickers)} —Ç–∏–∫–µ—Ä–æ–≤, {n_clusters} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤)")
            for i in range(n_clusters):
                members = [valid_tickers[j] for j, label in enumerate(cluster_labels) if label == i]
                print(f"   –ö–ª–∞—Å—Ç–µ—Ä {i}: {', '.join(members[:5])}{'...' if len(members) > 5 else ''} ({len(members)} —Ç–∏–∫–µ—Ä–æ–≤)")
            print()
            
            # –†–∞—Å—Å—ã–ª–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            if event_loop and connections["clusters"]:
                payload = {
                    "type": "clusters",
                    "data": cluster_results["clusters"],
                    "timestamp": cluster_results["last_update"]
                }
                asyncio.run_coroutine_threadsafe(broadcast_clusters(payload), event_loop)
                
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()

# =============== –¢–†–ï–ù–î–û–í–´–ô –ü–†–û–ì–ù–û–ó ===============
trend_history = defaultdict(lambda: deque(maxlen=60))  # –ò—Å—Ç–æ—Ä–∏—è —Ü–µ–Ω –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞

@app.websocket("/ws/trend-forecast")
async def websocket_trend(websocket: WebSocket):
    """–í–µ–±-—Å–æ–∫–µ—Ç –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø—Ä–æ–≥–Ω–æ–∑–∞ —Ç—Ä–µ–Ω–¥–∞"""
    await websocket.accept()
    connections["trend"] = connections.get("trend", set())
    connections["trend"].add(websocket)
    print(f"‚úÖ –¢—Ä–µ–Ω–¥–æ–≤—ã–π WebSocket –ø–æ–¥–∫–ª—é—á–µ–Ω. –ö–ª–∏–µ–Ω—Ç–æ–≤: {len(connections['trend'])}")
    
    try:
        while True:
            await websocket.receive_text()
    except WebSocketDisconnect:
        connections["trend"].discard(websocket)
        print(f"üîå –¢—Ä–µ–Ω–¥–æ–≤—ã–π WebSocket –æ—Ç–∫–ª—é—á–µ–Ω. –û—Å—Ç–∞–ª–æ—Å—å: {len(connections['trend'])}")

@app.get("/trend-forecast", response_class=HTMLResponse)
async def trend_forecast_page(request: Request):
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –ø—Ä–æ–≥–Ω–æ–∑–æ–º —Ç—Ä–µ–Ω–¥–∞"""
    return templates.TemplateResponse("trend_forecast.html", {"request": request})

async def broadcast_trend(data):
    """–†–∞—Å—Å—ã–ª–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ —Ç—Ä–µ–Ω–¥–µ"""
    disconnected = set()
    for ws in connections.get("trend", []):
        try:
            await ws.send_json(data)
        except:
            disconnected.add(ws)
    
    for ws in disconnected:
        connections["trend"].discard(ws)

@app.on_event("startup")
async def startup_event():
    global event_loop
    event_loop = asyncio.get_running_loop()
    
    print("\n" + "="*70)
    print("üöÄ –í–ï–ë-–°–ï–†–í–ï–† –ó–ê–ü–£–©–ï–ù (—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤–∞—à–∞ —Ä–∞–±–æ—á–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞)")
    print("="*70)
    print("   ‚Ä¢ –û—Å–Ω–æ–≤–Ω–æ–π –¥–∞—à–±–æ—Ä–¥: http://localhost:8000")
    print("   ‚Ä¢ –ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑: http://localhost:8000/clusters")
    print("   ‚Ä¢ –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞: http://localhost:8000/trend-forecast")
    print("   ‚Ä¢ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: –í–õ–û–ñ–ï–ù–ù–ê–Ø (–∫–∞–∫ –≤ –≤–∞—à–µ–º —Ä–∞–±–æ—á–µ–º –∫–æ–¥–µ)")
    print("   ‚Ä¢ auto_offset_reset: 'latest' (—Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ)")
    print("   ‚Ä¢ –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è: –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥")
    print("="*70 + "\n")
    
    Thread(target=kafka_reader, daemon=True).start()

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="warning")